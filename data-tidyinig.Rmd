---
title: "Data Reformatting"
author: "RFH"
date: "February 13, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r, warning = FALSE, message=FALSE}
library(tidyverse)

# to call stats filter - stats::filter()
```

#Reformat Catch Data
* Remove the "all" column
* Gather the different species into one "Species" column
    - move from wide to long
* General QA

It is possible to directly read in .csv files from a data repository by entering in the url link address. 

[Mike Byerly. Alaska commercial salmon catches by management region (1886- 1997). Gulf of Alaska Data Portal. df35b.304.2.](https://knb.ecoinformatics.org/view/df35b.304.2)

```{r}
catch_original<- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.302.1", method= "libcurl"), stringsAsFactors = FALSE)

head(catch_original)
```

Remove the "all" and "notesRegCode" columns using 'select' and piping to improve readability in the workflow.

Cnt + shift + m : pipe operator shortcup %>% 

When using gather, the key is the name of the new column created by condensing the long format columns.

```{r}
catch_long<-catch_original %>%
  select(Region, Year, Chinook, Sockeye, Coho, Pink, Chum) %>% 
  gather(key="Species", value = "Catch", -Region, -Year) #move from wide to long

#Another options is to deselect
catch_long_also<-catch_original %>%
  select(-All, -notesRegCode)

head(catch_long)

```
Just as an exercise, we can also reverse what we just did through 'spread'
```{r}
catch_wide <- catch_long %>% 
  spread(key=Species, value = Catch)

head(catch_wide)
```

## Clean up our data
* Rename catch to catch_thousands
* Change catch column to be numeric
* Create a new catch column in units num. of fish `#`

To make life easier, it is best to seperate out the pipe segments into different steps.
```{r}
catch_clean <- catch_long %>%
  rename(catch_thousands = Catch) %>% 
  mutate(catch_thousands = ifelse(catch_thousands=="I", 1, catch_thousands)) %>% 
  mutate(catch_thousands = as.numeric(catch_thousands)) %>% 
  mutate(catch = catch_thousands * 1000) %>% 
  select(-catch_thousands)

head(catch_clean)
```
We also looked for where as.numeric failed but do not need to show the code.
```{r, eval=F, echo=F}
test<- as.numeric(catch_long$Catch)
i<- which(is.na(test) ==TRUE)
catch_long[i,]

```

## Split-Apply-Combine Strategy

* Calculate the mean catch by species

```{r}
species_mean<- catch_clean %>% 
  group_by(Species, Year) %>% #split
  summarise(catch_mean = mean(catch),#apply and combine
            num_obs=n(),
            se= (sd(catch))/sqrt(n())) %>% #add a data column
  arrange(-catch_mean) %>% #sorts data by decending order
  filter(Year>= 1990) #add in a filter component if we just want a subset of data.
  
head(species_mean)
```

#Join the Region Definitions

Read in the regions dataframe.
```{r}
region_defs <- read.csv(url("https://knb.ecoinformatics.org/knb/d1/mn/v2/object/df35b.303.1",
                            method = "libcurl"),
                        stringsAsFactors = FALSE) %>% 
    select(code, mgmtArea)

head(region_defs)
```
Now we can start with the actual join.
```{r}
catch_joined<- left_join(catch_clean, region_defs, by = c("Region" = "code"))
head(catch_joined)
```

#Misc. Functions
* Seperate
* Unite

We are first going to explore seperate with some dumby variables which have been created for this workshop. 

```{r}
dates_df <- data.frame(date = c("5/24/1930",
                                "5/25/1930",
                                "5/26/1930",
                                "5/27/1930",
                                "5/28/1930"),
                       stringsAsFactors = FALSE)

dates_split<- dates_df %>% 
  separate(date, into = c("month", "day", "year"), sep = "/", remove = F)#keeps the original column

head(dates_split)
```

```{r}
dates_unite<- dates_split %>% 
  unite(col=date_iso, year,month, day, sep= "-")

head(dates_unite)
```

